---
layout: page
---

![NIME Embedded AI Header Image]({% link assets/nime-embedded-ai-web.jpg %})

Embedded computing technologies have long been present in NIME but it is
challenging to deploy AI and machine learning models on such systems. In
this hands-on workshop, we will provide you with starting
points to develop your own NIMEs with embedded platforms and machine
learning models.

# Schedule

The workshop schedule is as follows (N.B.: order of presentation may change):

- Intro (30 minutes)
- [Raspberry Pi and IMPSy]({% link rpi.md %}) (2.5 hours)
- Lunch
- [pyBela, pyTorch, cross-compilation]({% link bela.md %}) (2.5 hours)
- Closing (30 minutes)

# Things to bring to the workshop

- Your own laptop and power brick
- A Raspberry Pi or Bela (if you have one) 
- A USB MIDI controller or MIDI sound source (if you have one and want to use it with the Raspberry Pi)

see the [setup page]({% link setup.md %}) for things you can do before the workshop to set up your laptop, Bela, or Raspberry Pi.


# Organisers

## [Charles Patrick Martin](https://charlesmartin.au)

Charles Martin is a computer scientist specialising in music technology,
creative AI and human-computer interaction at The Australian National
University, Canberra. Charles develops musical apps such as PhaseRings,
researches creative AI, and performs music with Ensemble Metatone and
Andromeda is Coming. At the ANU, Charles teaches creative computing and
leads research into intelligent musical instruments. His lab's focus is
on developing new intelligent instruments, performing new music with
them, and bringing them to a broad audience of musicians and performers.
Charles has presented workshops on AI/ML and NIMEs at NIME 2019, 2020,
and 2021 and is an organiser of the Generative AI and HCI workshops at
CHI 2022, 2023, and 2024.

## [Teresa Pelinski](https://teresapelinski.com/)

Teresa Pelinski is a PhD student at the Augmented Instruments Lab at the
Centre for Digital Music, based in Queen Mary University of London.
Teresa's research focuses on developing tools for prototyping with ML in
the context of musical practice, and on doing so from a practice
research lens. Currently, she is also an Enrichment Student at the Alan
Turing Institute. Teresa holds a BSc in Physics from the Universidad
Aut√≥noma de Madrid and a MSc in Sound and Music Computing (MSc) from
Universitat Pompeu Fabra in Barcelona. Teresa was an organiser of the
Embedded AI for NIME 2022 workshop.

{% comment %}
# Technical and space requirements

-   Projection screen and sound system for slides and presentations from
    laptop.
-   Class or tutorial room with space for laptops and discussions.
-   Internet connections for all participants (for downloading code):
    preferably a simple ethernet connection to run a basic wireless
    router in the room
-   Power strips for plugging in laptops.

**Presentation Mode:** This will be an in-person workshop

{% endcomment %}

# Links

The workshop will build on materials used in previous NIME workshops and
classes at the presenters' institutions, e.g.:

-   Making Predictive NIMEs with Neural Networks:
    <https://creativeprediction.xyz/workshop/>

-   Embedded AI for NIME: <https://embedded-ai-for-nime.github.io/>

-   Critical Perspectives on AI/ML in Musical Interfaces:
    <https://critical-ml-music-interfaces.github.io/>

-   Sound and Music Computing: Generative AI and Computer Music:
    <https://comp.anu.edu.au/courses/laptop-ensemble/lectures/11-genai/>

[^1]: School of Computing, The Australian National University

[^2]: Centre for Digital Music, Queen Mary University of London
